# Decision Stumps

Decision stumps are a single part of a larger classifier called a decision tree
(wow, big surprise there Sherlock) in the same way a perceptron is the building
block of a neural network.

When many of them are put into a tree, one can feasibly make a model with an
extremely low error rate. Much of this is because of the nature of them; taking
data and splitting it into some number of categories based on a single feature
is useful -- even when not repeated.

Alas, I am at this point stumped (pun totally intended). There is a frustrating
lack of resources online pertaining solely to decision stumps in the context
that they were taught to me, and as such have been having difficulty grasping
the logic in *Understanding Machine Learning - From Theory to Algorithms*.
And since I'm relatively prideful, I'd rather put in the work at a later point
and understand it than try to hodge-podge someone else's work on decision trees
(which isn't even a stump) and pass it off as my own.

At this point, I'm going to concede as it has been many hours since I have slept
and I'm sure at least a few would do me well in wrestling the information given
in the book.
